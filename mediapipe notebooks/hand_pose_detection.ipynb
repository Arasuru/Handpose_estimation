{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "239a3e7d-196d-43f0-a2b2-c84ee88b95ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import uuid\n",
    "import os\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a51c0734-095d-4e3d-b08d-40018cf0ad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6452c9ed-bd21-4bf7-a2e7-2e4330f15a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables for recording video\n",
    "recording = False\n",
    "out = None\n",
    "all_landmarks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99e8c201-ff25-4a23-8f94-4358f421a9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the video file\n",
    "cap = cv2.VideoCapture(r\"C:\\Users\\ravik\\practice\\projects\\Hand Pose detection\\mediapipe videos\\OBS recordings\\participant_10.mkv\")\n",
    "\n",
    "# Video writer to save the processed video\n",
    "filename = f\"{uuid.uuid4()}.mp4\"\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(os.path.join(\"mediapipe videos\", filename), fourcc, fps, (frame_width, frame_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d24335c-f206-4b6e-b7c5-72d0f237289c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of video\n",
      "Processing and saving completed.\n"
     ]
    }
   ],
   "source": [
    "with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5,max_num_hands=2) as hands:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"End of video\")\n",
    "            break\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  #cv2 reads BGR format, mediapipe uses RGB format, so convert\n",
    "        image.flags.writeable =False\n",
    "\n",
    "        frame_width, frame_height = frame.shape[1], frame.shape[0]\n",
    "        landmarks_3d = [] #to store the xyz coordinates of each joint\n",
    "        #mediapipe processing the image\n",
    "        results = hands.process(image)\n",
    "\n",
    "        # Create a blank frame with the same dimensions as the video frame\n",
    "        blank_frame = np.zeros_like(frame)\n",
    "        \n",
    "        image.flags.writeable=True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if results.multi_hand_landmarks: #gives the coordinates of hand if a hand is detected\n",
    "            for num, hand in enumerate(results.multi_hand_landmarks):\n",
    "                mp_drawing.draw_landmarks(image, hand, mp_hands.HAND_CONNECTIONS,  #use image instead of blank_frame to save actual video\n",
    "                                         mp_drawing.DrawingSpec(color=(255, 0, 21), thickness=2, circle_radius=2), #for joints and dots\n",
    "                                         mp_drawing.DrawingSpec(color=(16, 255, 0), thickness=2, circle_radius=2)) #for connections and lines\n",
    "                #this is to store the x,y,z co-ordinates\n",
    "                for lm in hand.landmark:\n",
    "                    x = int(lm.x * frame_width)\n",
    "                    y = int(lm.y * frame_height)\n",
    "                    z = lm.z  # Depth can be scaled if needed\n",
    "                    landmarks_3d.append((x, y, z))\n",
    "\n",
    "                if recording and landmarks_3d:\n",
    "                    all_landmarks.append(landmarks_3d)  # Append current frame landmarks\n",
    "                    \n",
    "         # Save the processed frame to the video\n",
    "        out.write(image)\n",
    "\n",
    "    # Write landmarks to CSV file\n",
    "    datafile = filename.replace(\".mp4\", \".csv\")\n",
    "    with open(os.path.join(\"coordinates data\", datafile), mode='w', newline='') as f:\n",
    "        csv_writer = csv.writer(f)\n",
    "        header = [f'joint_{i}_{axis}' for i in range(21) for axis in ['x', 'y', 'z']]\n",
    "        csv_writer.writerow(header)\n",
    "        for frame_landmarks in all_landmarks:\n",
    "            row = [value for joint in frame_landmarks for value in joint]\n",
    "            csv_writer.writerow(row)\n",
    "            \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Processing and saving completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922b7934-b6b1-40fd-bc1f-58d6cec9c66c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
